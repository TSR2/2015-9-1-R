}
}
persent=sum(list=="F")/n
list(list,persent,mtotal)
}
##########################################
runs=function(run,fun,...){
v=rep(0,run)
for (i in 1:run){
v[i]=fun(...)[[2]]
}
mean(v)
}
################################################################
k=ifail(a=1,b=1,n=100)
runs(run = 500,fun = ifail,a=1,b=1,n=100)
runs(run = 500,fun = ifail,a=1,b=1,n=100)
runs(run = 500,fun = ifail,a=1,b=1,n=100)
runs(run = 1000,fun = ifail,a=1,b=1,n=100)
runs(run = 1000,fun = ifail,a=1,b=1,n=100)
runs(run = 200,fun = mstep,a=b1,b=b2,m=kn,n=500)
runs(run = 200,fun = mstep,alpha=0.9,m=kn,n=500,t=1)
runs(run = 200,fun = mstep,a=0.5,b=mm$root,m=kn,n=500)
runs(run = 200,fun = mstep,alpha=0.9,m=kn,n=500,t=1)
runs(run = 200,fun = mstep,a=a,b=mm$root,m=kn,n=500)
runs(run = 200,fun = mstep,alpha=0.9,m=kn,n=500,t=1)
runs(run = 200,fun = mstep,a=0.5,b=mm$root,m=kn,n=500)
runs(run = 200,fun = mstep,alpha=0.9,m=kn,n=500,t=1)
bb=function(a,b){
a/(a+b)-mf
}
a=0.5
mm=uniroot(bb,c(0,10),a=a)
mm$root
betavar(a,mm$root)
vf
runs(run = 200,fun = mstep,a=0.5,b=mm$root,m=kn,n=500)
runs(run = 200,fun = mstep,alpha=0.9,m=kn,n=500,t=1)
##varTL>varBETA
a=2
mm=uniroot(bb,c(0,10),a=a)
mm$root
betavar(a,mm$root)
vf
runs(run = 200,fun = mstep,a=a,b=mm$root,m=kn,n=500)
runs(run = 200,fun = mstep,alpha=0.9,m=kn,n=500,t=1)
runs(run = 500,fun = kfail,a=1,b=1,n=200,t=0)
v=0
for (i in 1:500){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/500
v=rep(0,500)
for (i in 1:500){
v[i]=mstep(a=1,b=1,m=44,t=1,n=200)[[2]]
}
mean(v)
v=rep(0,500)
for (i in 1:500){
v[i]=mstep(a=1,b=1,m=5,t=1,n=200)[[2]]
}
mean(v)
v=rep(0,500)
for (i in 1:500){
v[i]=mstep(a=1,b=1,m=5,t=0,n=200)[[2]]
}
mean(v)
v=rep(0,500)
for (i in 1:500){
v[i]=mstep(a=1,b=1,m=5,t=0,n=200)[[2]]
}
mean(v)
v=rep(0,500)
for (i in 1:500){
v[i]=mstep(a=1,b=1,m=5,t=0,n=200)[[2]]
}
mean(v)
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
v=0
for (i in 1:100){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/100
v=0
for (i in 1:100){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/100
v=0
for (i in 1:100){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/100
v=0
for (i in 1:100){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/100
v=0
for (i in 1:100){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/100
v=0
for (i in 1:100){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/100
v=0
for (i in 1:100){
a=kfail(a=1,b=1,n=200,t=0)$persent
v=v+a
}
v/100
runs(run = 100,fun = 'kfail',a=1,b=1,n=200,t=0)
print(rbeta(n = 1000,2,1))
plot(rbeta(n = 1000,2,1))
density(rbeta(n = 1000,2,1))
plot(density(rbeta(n = 1000,2,1)))
plot(density(rbeta(n = 10000,2,1)))
runs(run = 100,fun = as.formula(kfail),a=1,b=1,n=200,t=0)
runs(run = 100,fun = eval(parse(text="kfail")),a=1,b=1,n=200,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = mstep,a=1,b=1,n=200,t=0)
runs(run = 100,fun = mreducestep,a=1,b=1,n=200,t=0)
runs(run = 100,fun = Nkfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = ifail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = mstep,a=1,b=1,m=4,n=200,t=0)
runs(run = 100,fun = mreducestep,a=1,b=1,m=4,n=200,t=0)
runs(run = 100,fun = Nkfail,a=1,b=1,n=200,N=50,t=0)
runs(run = 100,fun = ifail,a=1,b=1,n=200,t=0)
n=100;a=0.9
rn=(2*n*a)^(1/3)
kn=((n*sqrt(pi))/(4*sqrt(a)))^(2/3)
kn=floor(kn)
Nn=kn*sum(sapply(0:(n-1),aaa,a=0.9))
?learn
??LearnBayes
install.packages("LearnBayes")
??LearnBayes
?LearnBayes
help.search("LearnBayes")
help.search("Bayes")
vf
b1=ll[[2]][1]
b2=ll[[2]][2]
b1/(b1+b2)
mf=mean(f)
mf
betavar(a,mm$root)
vf
mm$root
library(LearnBayes)
?optimx
??optimx
install.packages("optimx")
runs(run = 100,fun = kfail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = mstep,a=1,b=1,m=4,n=200,t=0)
runs(run = 100,fun = mreducestep,a=1,b=1,m=4,n=200,t=0)
runs(run = 100,fun = Nkfail,a=1,b=1,n=200,N=50,t=0)
runs(run = 100,fun = ifail,a=1,b=1,n=200,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=100,t=0)
runs(run = 100,fun = mstep,a=1,b=1,m=rn,n=100,t=0)
runs(run = 100,fun = mreducestep,a=1,b=1,m=kn,n=100,t=0)
runs(run = 100,fun = Nkfail,a=1,b=1,n=100,N=Nn,t=0)
runs(run = 100,fun = ifail,a=1,b=1,n=100,t=0)
runs(run = 100,fun = kfail,a=1,b=1,n=100,t=0)
runs(run = 100,fun = mstep,a=1,b=1,m=rn,n=100,t=0)
runs(run = 100,fun = mreducestep,a=1,b=1,m=kn,n=100,t=0)
runs(run = 100,fun = Nkfail,a=1,b=1,n=100,N=Nn,t=0)
runs(run = 100,fun = ifail,a=1,b=1,n=100,t=0)
[1+3]^2
L=function(a,b){
gamma(a+b)/(gamma(a)*gamma(b+1))
}
calculateM=function(a,b,n){
((n*gamma(1+1/b))/(b*L(a,b)^(1/b)))^(b/1+b)
}
calculateM(a=1,b=1,n=100)
calculateM(a=1,b=1,n=1000)
calculateM(a=1,b=1,n=10)
L(1,1)
calculateM(a=1,b=1,n=100)
L=function(a,b){
gamma(a+b)/(gamma(a)*gamma(b+1))
}
calculateM=function(a,b,n){
((n*gamma(1+1/b))/(b*L(a,b)^(1/b)))^(b/(1+b))
}
calculateM(a=1,b=1,n=100)
calculateM(a=1,b=2,n=500)
library(xtable)
install.packages("stargazer")
library(stargazer)
stargazer(iris)
xtable(iris)
mtcars
xtable(mtcars)
library(lattice)
PRIOR=data.frame("prior",p,prior)
POST=data.frame("posterior",p,post)
names(PRIOR)=c("Type","P","Probability")
names(POST)=c("Type","P","Probability")
data=rbind(PRIOR,POST)
xyplot(Probability~P|Type,data=data,layout=c(1,2),
type="h",lwd=3,col="black")
a = 3.26
b = 7.19
s = 11
f = 16
curve(dbeta(x,a+s,b+f), from=0, to=1,
+ xlab="p",ylab="Density",lty=1,lwd=4)
curve(dbeta(x,s+1,f+1),add=TRUE,lty=2,lwd=4)
curve(dbeta(x,a,b),add=TRUE,lty=3,lwd=4)
legend(.7,4,c("Prior","Likelihood","Posterior"),
lty=c(3,2,1),lwd=c(3,3,3))
midpt = seq(0.05, 0.95, by = 0.1)
prior = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
+ ylab="Prior density",ylim=c(0,.3))
library(lattice)
midpt = seq(0.05, 0.95, by = 0.1)
prior = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
+ ylab="Prior density",ylim=c(0,.3))
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
library(LearnBayes)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
p = seq(0, 1, length=500)
post = histprior(p, midpt, prior) *
dbeta(p, s+1, f+1)
post = post/sum(post)
ps = sample(p, replace = TRUE, prob = post)
hist(ps, xlab="p", main="")
?sample
p = seq(0,1, by = 0.125)
prior = c(.001 ,.001 ,.950 ,.008 ,.008 ,.008 ,.008 ,.008 ,.008)
prior = prior/sum(prior)
plot(p, prior, type = "h", ylab="Prior Probability")
data = c(6, 4)
post = pdisc(p, prior, data)
post
round(cbind(p, prior, post),2)
##########################################################ex1
p = seq(0,1, by = 0.125)
prior = c(.001 ,.001 ,.950 ,.008 ,.008 ,.008 ,.008 ,.008 ,.008)
prior = prior/sum(prior)
plot(p, prior, type = "h", ylab="Prior Probability")
library(LearnBayes)
data = c(6, 4)
post = pdisc(p, prior, data)
round(cbind(p, prior, post),2)
midpt = seq(0,1, by = 0.1)
prior = c(0.01, 0.01, 0.02, 0.3, 0.6, 0.3, 0.02, 0.01, 0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
midpt = seq(0,1, by = 0.1)
prior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
prior
prior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01,0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
prior
quantile2=list(p=.5,x=.377)
quantile1=list(p=.1,x=.006)
beta.select(quantile1,quantile2)
library(LearnBayes)
midpt = seq(0,1, by = 0.1)
prior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01,0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
s=5
f=15
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
p = seq(0, 1, by = 0.1)
post = histprior(p, midpt, prior) *
dbeta(p, s+1, f+1)
post = post/sum(post)
ps = sample(p, replace = TRUE, prob = post)
hist(ps, xlab="p", main="")
beta.select(quantile1,quantile2)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
hist(ps, xlab="p", main="")
par(mfrow=c(1,3))
library(LearnBayes)
midpt = seq(0,1, by = 0.1)
prior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01,0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
s=5
f=15
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
p = seq(0, 1, by = 0.1)
post = histprior(p, midpt, prior) *
dbeta(p, s+1, f+1)
post = post/sum(post)
ps = sample(p, replace = TRUE, prob = post)
hist(ps, xlab="p", main="")
x
par(mfrow=c(1,3))
library(LearnBayes)
midpt = seq(0,1, by = 0.1)
prior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01,0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
s=10
f=10
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
p = seq(0, 1, by = 0.1)
post = histprior(p, midpt, prior) *
dbeta(p, s+1, f+1)
post = post/sum(post)
ps = sample(p, replace = TRUE, prob = post)
hist(ps, xlab="p", main="")
par(mfrow=c(1,3))
library(LearnBayes)
midpt = seq(0,1, by = 0.1)
prior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01,0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
s=5
f=15
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
p = seq(0, 1, by = 0.1)
post = histprior(p, midpt, prior) *
dbeta(p, s+1, f+1)
post = post/sum(post)
ps = sample(p, replace = TRUE, prob = post)
hist(ps, xlab="p", main="")
ab=c(3.26, 7.19)
m=20; ys=0:20
pred=pbetap(ab, m, ys)
pred
pbeta(0:20,shape1 = 3.26,shape2 = 7.19)
dbeta(0:20,shape1 = 3.26,shape2 = 7.19)
p=rbeta(1000, 3.26, 7.19)
y = rbinom(1000, 20, p)
table(y)
table(y)
freq=table(y)
ys=as.integer(names(freq))
predprob=freq/sum(freq)
plot(ys,predprob,type="h",xlab="y",
+ ylab="Predictive Probability")
plot(ys,predprob,type="h",xlab="y",
ylab="Predictive Probability")
par(mfrow=c(1,1))
p=rbeta(1000, 3.26, 7.19)
y = rbinom(1000, 20, p)
table(y)
freq=table(y)
ys=as.integer(names(freq))
predprob=freq/sum(freq)
plot(ys,predprob,type="h",xlab="y",
ylab="Predictive Probability")
?rbinom
rbinom(10,2,0.5)
rbinom(10,2,c(0.5,0.2))
rbinom(10,1,c(0.5,0.2))
rbinom(10,1,c(0,1))
y
freq
ys=as.integer(names(freq))
predprob
predprob
sum(predprob[1:11])
sum(predprob[1:12])
qbeta(p = 1,shape1 = 23,shape2 = 8)
qbeta(p = 0.1,shape1 = 23,shape2 = 8)
?qbeta
qbeta(p = 0.2,shape1 = 23,shape2 = 8)
qbeta(p = 0.3,shape1 = 23,shape2 = 8)
qbeta(p = 0.5,shape1 = 23,shape2 = 8)
qbeta(p = 0.8,shape1 = 23,shape2 = 8)
qbeta(p = 0.9,shape1 = 23,shape2 = 8)
qbeta(p = 0.98,shape1 = 23,shape2 = 8)
qbeta(p = 0.99,shape1 = 23,shape2 = 8)
qbeta(p =1,shape1 = 23,shape2 = 8)
for (i in seq(0.99,0.9999,length.out = 10)){
print(qbeta(p =i,shape1 = 23,shape2 = 8))
}
pbeta(0.6,shape1 = 23,shape2 = 8)
pbeta(0.9,shape1 = 23,shape2 = 8)
for (i in seq(0.8,0.9,length.out = 20)){
print(pbeta(i,shape1 = 23,shape2 = 8))
}
for (i in seq(0.6,0.8,length.out = 30)){
print(pbeta(i,shape1 = 23,shape2 = 8))
}
for (i in seq(0.99,0.9999,length.out = 10)){
print(qbeta(p =i,shape1 = 23,shape2 = 8))
}
qbeta(c(0.05,0.95),shape1 = 23,shape2 = 8)
for (i in seq(0.6,0.8,length.out = 30)){
print(pbeta(i,shape1 = 23,shape2 = 8))
}
rbeta(1000,shape1 = 23,shape2 = 8)
pbeta(i,shape1 = 23,shape2 = 8)
for (i in seq(0.6,0.8,length.out = 30)){
print(pbeta(i,shape1 = 23,shape2 = 8))
}
for (i in seq(0.6,0.8,length.out = 30)){
print(c(i,pbeta(i,shape1 = 23,shape2 = 8)))
}
rbeta(1000,shape1 = 23,shape2 = 8)
p=rbeta(1000,shape1 = 23,shape2 = 8)
y = rbinom(1000, 10, p)
y
table(y)
fr[7:8]
fr=table(y)
fr[7:8]
sum(fr[7:8])/sum(fr)
fr=table(y)
sum(fr[7:8])/sum(fr)
library(plyr)
library(dplyr)
library(magrittr)
library(LearnBayes)
lambda=c(.5, 1, 1.5, 2, 2.5,3)
midpt = seq(0,1, by = 0.1)
prior=c(.1, .2, .3, .2, .15,0.05)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
par(mfrow=c(1,3))
library(LearnBayes)
midpt = seq(0,1, by = 0.1)
prior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01,0.01)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
s=5
f=15
curve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),
from=0, to=1, ylab="Posterior density")
p = seq(0, 1, by = 0.1)
post = histprior(p, midpt, prior) *
dbeta(p, s+1, f+1)
post = post/sum(post)
ps = sample(p, replace = TRUE, prob = post)
hist(ps, xlab="p", main="")
midpt = c(.5, 1, 1.5, 2, 2.5,3)
prior=c(.1, .2, .3, .2, .15,0.05)
prior = prior/sum(prior)
curve(histprior(x,midpt,prior), from=0, to=1,
ylab="Prior density",ylim=c(0,.3))
post=aaa(prior,6,2,12)
aaa=function(g,t,lamb,y){
g*exp(-t*lamb)*(t*lamb)^y
}
post=aaa(prior,6,2,12)
ddd=cbind(midpt,prior,post)
ddd
post=aaa(prior,6,midpt,12)
ddd=cbind(midpt,prior,post)
ddd
post=aaa(prior,6,midpt,12)
post=post/sum(post)
ddd=cbind(midpt,prior,post)
ddd
bpost=aaa(prior,-7,midpt,0)
bpost
bpost %>% sum
bpost
bpost=aaa(prior,7,midpt,0)
bpost
bpost %>% sum
bpost =bpost/sum(bpost)
bpost*exp(-7*midpt) %>% sum
kk=bpost*exp(-7*midpt)
kk%>% sum()
