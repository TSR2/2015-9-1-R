{
    "contents" : "library(plyr)\nlibrary(dplyr)\nlibrary(magrittr)\n\nxx=read.table(\"C:/Users/tsr/Desktop/上課用檔案/貝氏計算/studentdata.txt\",header=T)\n\nhead(xx)\nxx %>% dim()\n\n\nxx$hours.of.sleep = xx$WakeUp - xx$ToSleep\nplot(jitter(xx$ToSleep),jitter(xx$hours.of.sleep))\n\n\ntstatistic=function(x,y)\n{\n  m=length(x)\n  n=length(y)\n  sp=sqrt(((m-1)*sd(x)^2+(n-1)*sd(y)^2)/(m+n-2))\n  t.stat=(mean(x)-mean(y))/(sp*sqrt(1/m+1/n))\n  return(t.stat)\n}\n\nm=10; n=10\nmy.tsimulation=function(){\n  tstatistic(rnorm(m,mean=10,sd=2), rexp(n,rate=1/10))\n}\n\ntstat.vector=replicate(10000, my.tsimulation())\n\nplot(density(tstat.vector),xlim=c(-5,8),ylim=c(0,.4),lwd=3)\ncurve(dt(x,df=18),add=TRUE)\nlegend(4,.3,c(\"exact\",\"t(18)\"),lwd=c(3,1))\n\nbinom.test(0.4,100,0.5,conf.level = 0.9)\n\nbinomial.conf.interval=function(y,n)\n{\n  z=qnorm(.95)\n  phat=y/n\n  se=sqrt(phat*(1-phat)/n)\n  return(c(phat-z*se,phat+z*se))\n}\ndd=rbinom(n=20,1,prob=.5)\n\ninter=binomial.conf.interval(sum(dd),20)\na=c()\nfor (i in 1:100){\n  dd1=rbinom(n=20,1,prob=.5)\n  a[i]=mean(dd1)\n}\n\nsum(a<=inter[2] & a>=inter[1])\n\n\n\n\nasd=function(n,p,m){\n  dd=rbinom(n=m,1,prob=.5)\n  inter=binomial.conf.interval(sum(dd),m)\n  a=c()\n  for (i in 1:10000){\n    dd1=rbinom(n=m,1,prob=p)\n    a[i]=mean(dd1)\n  }\n}\n\n#####chapter2\n\np = seq(0.05, 0.95, by = 0.1)\nprior = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)\nprior = prior/sum(prior)\nplot(p, prior, type = \"h\", ylab=\"Prior Probability\")\nlibrary(LearnBayes)\ndata = c(11, 16)\npost = pdisc(p, prior, data)\nround(cbind(p, prior, post),2)\n\nlibrary(lattice)\nPRIOR=data.frame(\"prior\",p,prior)\nPOST=data.frame(\"posterior\",p,post)\nnames(PRIOR)=c(\"Type\",\"P\",\"Probability\")\nnames(POST)=c(\"Type\",\"P\",\"Probability\")\ndata=rbind(PRIOR,POST)\nxyplot(Probability~P|Type,data=data,layout=c(1,2),\n          type=\"h\",lwd=3,col=\"black\")\n\n\n\n\na = 3.26\nb = 7.19\ns = 11\nf = 16\ncurve(dbeta(x,a+s,b+f), from=0, to=1,\n        + xlab=\"p\",ylab=\"Density\",lty=1,lwd=4)\ncurve(dbeta(x,s+1,f+1),add=TRUE,lty=2,lwd=4)\ncurve(dbeta(x,a,b),add=TRUE,lty=3,lwd=4)\nlegend(.7,4,c(\"Prior\",\"Likelihood\",\"Posterior\"),\n         lty=c(3,2,1),lwd=c(3,3,3))\n\n\n\nlibrary(LearnBayes)\n midpt = seq(0.05, 0.95, by = 0.1)\nprior = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)\nprior = prior/sum(prior)\ncurve(histprior(x,midpt,prior), from=0, to=1,\n        ylab=\"Prior density\",ylim=c(0,.3))\n\ncurve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),\n      from=0, to=1, ylab=\"Posterior density\")\n\np = seq(0, 1, by = 0.125)\npost = histprior(p, midpt, prior) *\n  dbeta(p, s+1, f+1)\npost = post/sum(post)\nps = sample(p, replace = TRUE, prob = post)\nhist(ps, xlab=\"p\", main=\"\")\n\n\n\n\n##########################################################ex1\np = seq(0,1, by = 0.125)\nprior = c(.001 ,.001 ,.950 ,.008 ,.008 ,.008 ,.008 ,.008 ,.008)\nprior = prior/sum(prior)\nplot(p, prior, type = \"h\", ylab=\"Prior Probability\")\nlibrary(LearnBayes)\ndata = c(6, 4)\npost = pdisc(p, prior, data)\nround(cbind(p, prior, post),2)\n\nlibrary(lattice)\nPRIOR=data.frame(\"prior\",p,prior)\nPOST=data.frame(\"posterior\",p,post)\nnames(PRIOR)=c(\"Type\",\"P\",\"Probability\")\nnames(POST)=c(\"Type\",\"P\",\"Probability\")\ndata=rbind(PRIOR,POST)\nxyplot(Probability~P|Type,data=data,layout=c(1,2),\n       type=\"h\",lwd=3,col=\"black\")\n\n\n\n\n############################ex2\npar(mfrow=c(1,3))\nlibrary(LearnBayes)\nmidpt = seq(0,1, by = 0.1)\nprior = c(0.01, 0.01, 0.02, 0.3, 0.3,0.6, 0.3, 0.02, 0.01, 0.01,0.01)\nprior = prior/sum(prior)\ncurve(histprior(x,midpt,prior), from=0, to=1,\n      ylab=\"Prior density\",ylim=c(0,.3))\ns=5\nf=15\ncurve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),\n      from=0, to=1, ylab=\"Posterior density\")\n\np = seq(0, 1, by = 0.1)\npost = histprior(p, midpt, prior) *\n  dbeta(p, s+1, f+1)\npost = post/sum(post)\nps = sample(p, replace = TRUE, prob = post)\nhist(ps, xlab=\"p\", main=\"\")\n\n\n\n\n\n####################################\nab=c(3.26, 7.19)\nm=20; ys=0:20\npred=pbetap(ab, m, ys)\n\npar(mfrow=c(1,1))\np=rbeta(1000, 3.26, 7.19)\ny = rbinom(1000, 20, p)\ntable(y)\nfreq=table(y)\nys=as.integer(names(freq))\npredprob=freq/sum(freq)\nplot(ys,predprob,type=\"h\",xlab=\"y\",\n        ylab=\"Predictive Probability\")\nsum(predprob[1:12])\n\n####################################\n\nqbeta(c(0.05,0.95),shape1 = 23,shape2 = 8)\nfor (i in seq(0.6,0.8,length.out = 30)){\n  print(c(i,pbeta(i,shape1 = 23,shape2 = 8)))\n}\n\np=rbeta(1000,shape1 = 23,shape2 = 8)\ny = rbinom(1000, 10, p)\nfr=table(y)\nsum(fr[7:8])/sum(fr)\n\n#############################q6\nlambda=c(.5, 1, 1.5, 2, 2.5,3)\n\nmidpt = c(.5, 1, 1.5, 2, 2.5,3)\nprior=c(.1, .2, .3, .2, .15,0.05)\n\naaa=function(g,t,lamb,y){\n  g*exp(-t*lamb)*(t*lamb)^y\n}\n\n#######因為天數是六天，次數是12\npost=aaa(prior,6,midpt,12)\npost=post/sum(post)\n\nddd=cbind(midpt,prior,post)\nddd\n\n####q6b\nbpost=aaa(prior,7,midpt,0)\n\nbpost =bpost/sum(bpost)\nkk=bpost*exp(-7*midpt)\nkk %>% sum()\n\n\n\ns=5\nf=15\ncurve(histprior(x,midpt,prior) * dbeta(x,s+1,f+1),\n      from=0, to=1, ylab=\"Posterior density\")\n\np = seq(0, 1, by = 0.1)\npost = histprior(p, midpt, prior) *\n  dbeta(p, s+1, f+1)\npost = post/sum(post)\nps = sample(p, replace = TRUE, prob = post)\nhist(ps, xlab=\"p\", main=\"\")\n\ndata = c(11, 16)\npost = pdisc(p, prior, data)\nround(cbind(p, prior, post),2)\n\n########ch3\ndata(footballscores)\nxx=footballscores\nhead(xx)\nattach(xx)\nd = favorite - underdog - spread\nn = length(d)\nv = sum(d^2)\n\np = rchisq(1000, n)/v\ns = sqrt(1/p)\nhist(s,main=\"\")\n\nquantile(s, probs = c(0.025, 0.5, 0.975))\n\n#p43\nalpha=16;beta=15174\nyobs=1; ex=66\ny=0:10\nlam=alpha/beta\npy=dpois(y, lam*ex)*dgamma(lam, shape = alpha,\n                            rate = beta)/dgamma(lam, shape= alpha + y,\n                            rate = beta + ex)\ncbind(y, round(py, 3))\n\nlambdaA = rgamma(1000, shape = alpha + yobs, rate = beta + ex)\n\nex = 1767; yobs=4\ny = 0:10\npy = dpois(y, lam * ex) * dgamma(lam, shape = alpha,\n                                 rate = beta)/dgamma(lam, shape = alpha + y,\n                                rate = beta + ex)\ncbind(y, round(py, 3))\nlambdaB = rgamma(1000, shape = alpha + yobs, rate = beta + ex)\n\npar(mfrow = c(2, 1))\nplot(density(lambdaA), main=\"HOSPITAL A\",\n       xlab=\"lambdaA\", lwd=3)\n\ncurve(dgamma(x, shape = alpha, rate = beta), add=TRUE)\n\nlegend(\"topright\",legend=c(\"prior\",\"posterior\"),lwd=c(1,3))\n\nplot(density(lambdaB), main=\"HOSPITAL B\",\n        xlab=\"lambdaB\", lwd=3)\ncurve(dgamma(x, shape = alpha, rate = beta), add=TRUE)\nlegend(\"topright\",legend=c(\"prior\",\"posterior\"),lwd=c(1,3))\n\nquantile1=list(p=.5,x=100); quantile2=list(p=.95,x=120)\nnormal.select(quantile1, quantile2)\n\n\nmu = 100\ntau = 12.16\nsigma = 15\nn = 4\nse = sigma/sqrt(4)\nybar = c(110, 125, 140)\ntau1 = 1/sqrt(1/se^2 + 1/tau^2)\nmu1 = (ybar/se^2 + mu/tau^2) * tau1^2\nsumm1=cbind(ybar, mu1, tau1)\nsumm1\n\ntscale = 20/qt(0.95, 2)\ntscale\n\npar(mfrow=c(1,1))\ncurve(1/tscale*dt((x-mu)/tscale,2),\n      from=60, to=140, xlab=\"theta\", ylab=\"Prior Density\")\ncurve(dnorm(x,mean=mu,sd=tau), add=TRUE, lwd=3)\nlegend(\"topright\",legend=c(\"t density\",\"normal density\"),\n         lwd=c(1,3))\n\nnorm.t.compute=function(ybar) {\n  theta = seq(60, 180, length = 500)\n  like = dnorm(theta,mean=ybar,sd=sigma/sqrt(n))\n  prior = dt((theta - mu)/tscale, 2)\n  post = prior * like\n  post = post/sum(post)\n  m = sum(theta * post)\n  s = sqrt(sum(theta^2 * post) - m^2)\n  c(ybar, m, s) }\nsumm2=t(sapply(c(110, 125, 140),norm.t.compute))\ndimnames(summ2)[[2]]=c(\"ybar\",\"mu1 t\",\"tau1 t\")\nsumm2",
    "created" : 1452344736863.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "749821964",
    "id" : "EE11C435",
    "lastKnownWriteTime" : 1450151318,
    "path" : "C:/Users/TSR/Desktop/2015-9-1-R/bayes code/bayes/round 2.R",
    "project_path" : "round 2.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "type" : "r_source"
}